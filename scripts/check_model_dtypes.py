# check_model_dtypes.py
import os
import safetensors.torch as safetensors

def get_dtype_from_safetensors(path):
    """ä» .safetensors æ–‡ä»¶ä¸­è¯»å–ç¬¬ä¸€ä¸ªå¼ é‡çš„ dtype"""
    if not os.path.exists(path):
        return None, f"æ–‡ä»¶ä¸å­˜åœ¨: {path}"
    try:
        tensors = safetensors.load_file(path)
        if not tensors:
            return None, "æ–‡ä»¶ä¸­æ— å¼ é‡"
        first_key = next(iter(tensors.keys()))
        dtype = tensors[first_key].dtype
        return dtype, first_key
    except Exception as e:
        return None, f"åŠ è½½å¤±è´¥: {e}"

def main():
    # é…ç½®è·¯å¾„ï¼ˆè¯·æ ¹æ®ä½ çš„å®é™…è·¯å¾„ä¿®æ”¹ï¼‰
    lora_dir = "outputs/sft_1218_with_low_lr"
    merged_dir = "outputs/sft_merged_1218_with_low_lr"

    lora_path = os.path.join(lora_dir, "adapter_model.safetensors")
    merged_path = os.path.join(merged_dir, "model.safetensors")

    print("ğŸ” æ£€æŸ¥æ¨¡å‹ç²¾åº¦ (dtype)...\n")

    # æ£€æŸ¥ LoRA æƒé‡
    print("1. LoRA é€‚é…å™¨æƒé‡:")
    dtype, info = get_dtype_from_safetensors(lora_path)
    if dtype is not None:
        print(f"   - æ–‡ä»¶: {lora_path}")
        print(f"   - ç¤ºä¾‹å¼ é‡: {info}")
        print(f"   - ç²¾åº¦ (dtype): {dtype}")
    else:
        print(f"   âŒ {info}")

    print()

    # æ£€æŸ¥åˆå¹¶åçš„æ¨¡å‹
    print("2. åˆå¹¶åçš„å®Œæ•´æ¨¡å‹:")
    dtype, info = get_dtype_from_safetensors(merged_path)
    if dtype is not None:
        print(f"   - æ–‡ä»¶: {merged_path}")
        print(f"   - ç¤ºä¾‹å¼ é‡: {info}")
        print(f"   - ç²¾åº¦ (dtype): {dtype}")
    else:
        print(f"   âŒ {info}")

    print("\nâœ… æ£€æŸ¥å®Œæˆã€‚")

if __name__ == "__main__":
    main()