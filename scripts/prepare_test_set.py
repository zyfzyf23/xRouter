#!/usr/bin/env python3
"""
æ„å»ºæµ‹è¯•æ•°æ®é›†è„šæœ¬
ä» GSM8K æµ‹è¯•é›†å’Œæœ¬åœ° parquet æ–‡ä»¶ä¸­æå–æœªåœ¨è®­ç»ƒé›†ä¸­å‡ºç°çš„é¢˜ç›®
ç”Ÿæˆç‹¬ç«‹çš„æµ‹è¯•é›† data/test_set.jsonl
"""

import os
import json
import random
import re
from typing import Dict, Any, List, Set
from tqdm import tqdm
import pandas as pd
from datasets import load_dataset

def load_training_questions(raw_file: str) -> Set[str]:
    """
    åŠ è½½è®­ç»ƒé›†ä¸­çš„æ‰€æœ‰é—®é¢˜ï¼Œæ„å»ºé»‘åå•

    Args:
        raw_file: è®­ç»ƒé›†æ–‡ä»¶è·¯å¾„

    Returns:
        åŒ…å«æ‰€æœ‰è®­ç»ƒé›†é—®é¢˜çš„é›†åˆ
    """
    if not os.path.exists(raw_file):
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°è®­ç»ƒé›†æ–‡ä»¶ {raw_file}")
        return set()

    print(f"ğŸ“– æ­£åœ¨è¯»å–è®­ç»ƒé›† {raw_file}ï¼Œæ„å»ºé—®é¢˜é»‘åå•...")
    questions = set()

    with open(raw_file, 'r', encoding='utf-8') as f:
        for line in tqdm(f, desc="è¯»å–è®­ç»ƒé›†"):
            try:
                data = json.loads(line)
                question = data.get('question', '').strip()
                if question:
                    questions.add(question)
            except Exception as e:
                print(f"âš ï¸  è§£æè¡Œå¤±è´¥: {e}")

    print(f"âœ… æ„å»ºé»‘åå•å®Œæˆï¼ŒåŒ…å« {len(questions)} ä¸ªé—®é¢˜")
    return questions

def extract_content_from_prompt(prompt: Any) -> str:
    """
    ä» prompt å­—æ®µä¸­æå–ç”¨æˆ·é—®é¢˜å†…å®¹
    å…¼å®¹å¤šç§æ ¼å¼ï¼ˆå­—ç¬¦ä¸²ã€åˆ—è¡¨ã€JSONç­‰ï¼‰
    """
    import numpy as np
    import ast

    # é¢„å¤„ç†ï¼šå¤„ç† numpy æ•°ç»„æˆ–éå­—ç¬¦ä¸²ç±»å‹
    if isinstance(prompt, np.ndarray):
        prompt = prompt.tolist()

    # å¦‚æœå·²ç»æ˜¯åˆ—è¡¨ï¼Œç›´æ¥å¤„ç†
    if isinstance(prompt, list):
        return _extract_from_list_obj(prompt)

    # å¦‚æœä¸æ˜¯å­—ç¬¦ä¸²ï¼Œå¼ºè½¬å­—ç¬¦ä¸²
    if not isinstance(prompt, str):
        prompt = str(prompt)

    prompt = prompt.strip()

    # å¦‚æœä¸æ˜¯ä»¥åˆ—è¡¨å¼€å¤´ï¼Œç›´æ¥è¿”å›
    if not prompt.startswith('['):
        return prompt

    # å°è¯• JSON è§£æ
    try:
        parsed_obj = json.loads(prompt)
        if isinstance(parsed_obj, list):
            return _extract_from_list_obj(parsed_obj)
    except:
        pass

    # å°è¯• Python AST è§£æ
    try:
        parsed_obj = ast.literal_eval(prompt)
        if isinstance(parsed_obj, list):
            return _extract_from_list_obj(parsed_obj)
    except (ValueError, SyntaxError):
        pass

    # æ­£åˆ™è¡¨è¾¾å¼å¼ºåˆ¶æå–
    try:
        contents = re.findall(r"'content':\s*(['\"])(.*?)\1", prompt, re.DOTALL)
        roles = re.findall(r"'role':\s*(['\"])(.*?)\1", prompt, re.DOTALL)

        if len(contents) == len(roles):
            for i, (_, role_val) in enumerate(roles):
                if role_val == 'user':
                    return contents[i][1]

        # æŸ¥æ‰¾ "content": "...", "role": "user" ç»„åˆ
        match = re.search(r"'content':\s*(['\"])(.*?)\1,\s*'role':\s*'user'", prompt, re.DOTALL)
        if match:
            return match.group(2)
    except Exception:
        pass

    return prompt

def _extract_from_list_obj(data_list: list) -> str:
    """è¾…åŠ©å‡½æ•°ï¼šä»åˆ—è¡¨å¯¹è±¡ä¸­æå– content"""
    # ä¼˜å…ˆæ‰¾ user
    for item in data_list:
        if isinstance(item, dict) and item.get('role') == 'user':
            content = item.get('content', '')
            if 'Please output the final answer' in content:
                content = content.split('Please output the final answer')[0].strip()
            return content

    # æ²¡æ‰¾åˆ° userï¼Œè¿”å›ç¬¬ä¸€ä¸ªéç©º
    for item in data_list:
        if isinstance(item, dict):
            content = item.get('content', '')
            if content:
                return content.strip()
    return ""

def extract_ground_truth_from_parquet(sample: pd.Series) -> str:
    """ä» parquet æ ·æœ¬ä¸­æå–æ ‡å‡†ç­”æ¡ˆ"""
    if 'reward_model' in sample and pd.notna(sample['reward_model']):
        reward_model = sample['reward_model']
        if isinstance(reward_model, dict):
            gt = reward_model.get('ground_truth')
            if gt: return str(gt)
    if 'extra_info' in sample and pd.notna(sample['extra_info']):
        extra_info = sample['extra_info']
        if isinstance(extra_info, dict):
            ans = extra_info.get('answer')
            if ans: return str(ans)
    return ""

def extract_answer_from_gsm8k(answer_text: str) -> str:
    """
    ä» GSM8K çš„ answer å­—æ®µä¸­æå– #### åé¢çš„ç­”æ¡ˆ
    """
    if not isinstance(answer_text, str):
        answer_text = str(answer_text)

    # æŸ¥æ‰¾ #### åé¢çš„å†…å®¹
    match = re.search(r'####\s*([^\n]+)', answer_text)
    if match:
        return match.group(1).strip()

    # å¦‚æœæ²¡æœ‰æ‰¾åˆ° ####ï¼Œå°è¯•å…¶ä»–æ¨¡å¼
    patterns = [
        r'(?:The answer is|Answer:|Result:)\s*([^\n]+)',
        r'=\s*([^\n]+)$',
        r'([0-9]+(?:\.[0-9]+)?)\s*$'
    ]

    for pattern in patterns:
        match = re.search(pattern, answer_text, re.IGNORECASE)
        if match:
            return match.group(1).strip()

    # å¦‚æœéƒ½æ²¡æ‰¾åˆ°ï¼Œè¿”å›åŸå§‹æ–‡æœ¬çš„æœ€åéƒ¨åˆ†
    lines = answer_text.split('\n')
    for line in reversed(lines):
        line = line.strip()
        if line and not line.startswith('<<') and len(line) < 50:
            return line

    # é»˜è®¤è¿”å›åŸå§‹æ–‡æœ¬
    return answer_text.strip()

def load_gsm8k_test_set(blacklist: Set[str]) -> List[Dict]:
    """
    åŠ è½½ GSM8K æµ‹è¯•é›†ï¼Œè¿‡æ»¤æ‰è®­ç»ƒé›†ä¸­å·²æœ‰çš„é¢˜ç›®

    Args:
        blacklist: è®­ç»ƒé›†é—®é¢˜é»‘åå•

    Returns:
        GSM8K æµ‹è¯•é›†æ•°æ®åˆ—è¡¨
    """
    print(f"\nğŸ“¥ æ­£åœ¨ä» Hugging Face ä¸‹è½½ GSM8K æµ‹è¯•é›†...")

    try:
        # ä¸‹è½½ GSM8K æµ‹è¯•é›†
        dataset = load_dataset('openai/gsm8k', 'main', split='test')
        print(f"âœ… æˆåŠŸä¸‹è½½ GSM8K æµ‹è¯•é›†ï¼Œå…± {len(dataset)} æ¡æ•°æ®")
    except Exception as e:
        print(f"âŒ ä¸‹è½½ GSM8K æµ‹è¯•é›†å¤±è´¥: {e}")
        return []

    # è¿‡æ»¤æ•°æ®
    test_data = []
    skipped_count = 0

    for idx, sample in enumerate(tqdm(dataset, desc="è¿‡æ»¤ GSM8K æµ‹è¯•é›†")):
        question = sample.get('question', '').strip()
        answer = sample.get('answer', '')

        # æ£€æŸ¥æ˜¯å¦åœ¨é»‘åå•ä¸­
        if question in blacklist:
            skipped_count += 1
            continue

        # æå–ç­”æ¡ˆ
        ground_truth = extract_answer_from_gsm8k(answer)

        test_data.append({
            "id": f"test_gsm8k_{idx}",
            "domain": "math",
            "source": "gsm8k_test",
            "question": question,
            "ground_truth": ground_truth
        })

    print(f"âœ… GSM8K æµ‹è¯•é›†å¤„ç†å®Œæˆï¼šä¿ç•™ {len(test_data)} æ¡ï¼Œè·³è¿‡ {skipped_count} æ¡")
    return test_data

def load_hard_test_questions(parquet_file: str, blacklist: Set[str], num_samples: int = 500, seed: int = 42) -> List[Dict]:
    """
    ä» parquet æ–‡ä»¶ä¸­é‡‡æ ·å›°éš¾çš„æµ‹è¯•é¢˜

    Args:
        parquet_file: parquet æ–‡ä»¶è·¯å¾„
        blacklist: è®­ç»ƒé›†é—®é¢˜é»‘åå•
        num_samples: éœ€è¦é‡‡æ ·çš„æ•°é‡
        seed: éšæœºç§å­

    Returns:
        å›°éš¾æµ‹è¯•é¢˜æ•°æ®åˆ—è¡¨
    """
    if not os.path.exists(parquet_file):
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ° parquet æ–‡ä»¶ {parquet_file}")
        return []

    print(f"\nğŸ“– æ­£åœ¨è¯»å– parquet æ–‡ä»¶ {parquet_file}...")

    try:
        df = pd.read_parquet(parquet_file)
        print(f"âœ… æˆåŠŸè¯»å– {len(df)} æ¡æ•°æ®")
    except Exception as e:
        print(f"âŒ è¯»å– Parquet æ–‡ä»¶å¤±è´¥: {e}")
        return []

    # æ˜¾ç¤ºæ•°æ®æºåˆ†å¸ƒ
    print("\nğŸ“Š æ•°æ®æºåˆ†å¸ƒ:")
    source_counts = df['data_source'].value_counts()
    for source, count in source_counts.items():
        print(f"  - {source}: {count} æ¡")

    # ç­›é€‰åŒ…å« math æˆ– olympiad çš„æ•°æ®æº
    print("\nğŸ” æ­£åœ¨ç­›é€‰å›°éš¾é¢˜ç›®...")
    mask = df['data_source'].str.contains('math', case=False, na=False)
    filtered_df = df[mask]
    print(f"âœ… æ‰¾åˆ° {len(filtered_df)} æ¡å€™é€‰é¢˜ç›®")

    # è¿›ä¸€æ­¥è¿‡æ»¤ï¼šæå–é—®é¢˜å¹¶æ£€æŸ¥é»‘åå•
    valid_samples = []
    for _, sample in filtered_df.iterrows():
        question = extract_content_from_prompt(sample['prompt']).strip()
        if question and question not in blacklist:
            sample_dict = sample.to_dict()
            sample_dict['extracted_question'] = question
            valid_samples.append(sample_dict)

    print(f"âœ… è¿‡æ»¤é»‘åå•åå‰©ä½™ {len(valid_samples)} æ¡é¢˜ç›®")

    # éšæœºé‡‡æ ·
    if len(valid_samples) < num_samples:
        print(f"âš ï¸  å¯ç”¨é¢˜ç›®ä¸è¶³ {num_samples} æ¡ï¼Œä»…ä½¿ç”¨ {len(valid_samples)} æ¡")
        sampled_samples = valid_samples
    else:
        print(f"ğŸ² æ­£åœ¨éšæœºé‡‡æ · {num_samples} æ¡é¢˜ç›®...")
        random.seed(seed)
        sampled_samples = random.sample(valid_samples, num_samples)

    # å¤„ç†é‡‡æ ·æ•°æ®
    hard_test_data = []
    for idx, sample in enumerate(sampled_samples):
        question = sample['extracted_question']
        ground_truth = extract_ground_truth_from_parquet(pd.Series(sample))

        hard_test_data.append({
            "id": f"test_hard_{idx}",
            "domain": "math",
            "source": "hard_test",
            "question": question,
            "ground_truth": ground_truth
        })

    print(f"âœ… æˆåŠŸå¤„ç† {len(hard_test_data)} æ¡å›°éš¾æµ‹è¯•é¢˜")
    return hard_test_data

def save_test_set(gsm8k_data: List[Dict], hard_data: List[Dict], output_file: str):
    """
    ä¿å­˜æµ‹è¯•é›†åˆ°æ–‡ä»¶

    Args:
        gsm8k_data: GSM8K æµ‹è¯•é›†æ•°æ®
        hard_data: å›°éš¾æµ‹è¯•é¢˜æ•°æ®
        output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
    """
    # åˆå¹¶æ•°æ®
    all_data = gsm8k_data + hard_data
    print(f"\nğŸ”— æµ‹è¯•é›†åˆå¹¶å®Œæˆï¼Œæ€»è®¡ {len(all_data)} æ¡")
    print(f"   - GSM8K æµ‹è¯•é¢˜: {len(gsm8k_data)} æ¡")
    print(f"   - å›°éš¾æµ‹è¯•é¢˜: {len(hard_data)} æ¡")

    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(os.path.dirname(output_file), exist_ok=True)

    # ä¿å­˜åˆ°æ–‡ä»¶
    print(f"\nğŸ’¾ æ­£åœ¨ä¿å­˜åˆ° {output_file}...")

    with open(output_file, 'w', encoding='utf-8') as f:
        for data in tqdm(all_data, desc="ä¿å­˜æµ‹è¯•é›†"):
            f.write(json.dumps(data, ensure_ascii=False) + '\n')

    print(f"\nâœ… æµ‹è¯•é›†å·²æˆåŠŸä¿å­˜åˆ° {output_file}ï¼")

    # æ˜¾ç¤ºè¾“å‡ºç¤ºä¾‹
    print("\nğŸ“„ æµ‹è¯•é›†æ ¼å¼ç¤ºä¾‹:")
    print("\nGSM8K æµ‹è¯•é¢˜ç¤ºä¾‹:")
    if gsm8k_data:
        example = gsm8k_data[0]
        print(f"  - ID: {example['id']}")
        print(f"  - Source: {example['source']}")
        print(f"  - Question: {example['question'][:100]}...")
        print(f"  - Answer: {example['ground_truth']}")

    print("\nå›°éš¾æµ‹è¯•é¢˜ç¤ºä¾‹:")
    if hard_data:
        example = hard_data[0]
        print(f"  - ID: {example['id']}")
        print(f"  - Source: {example['source']}")
        print(f"  - Question: {example['question'][:100]}...")
        print(f"  - Answer: {example['ground_truth']}")

def main():
    """ä¸»å‡½æ•°"""
    # é…ç½®å‚æ•°
    TRAIN_FILE = "data/raw_prompts.jsonl"
    PARQUET_FILE = "data/train/math__combined_54.4k.parquet"
    OUTPUT_FILE = "data/test_set.jsonl"
    NUM_HARD_SAMPLES = 500
    RANDOM_SEED = 42

    print("=" * 60)
    print("æ„å»ºæµ‹è¯•æ•°æ®é›†è„šæœ¬")
    print("=" * 60)
    print("ç›®æ ‡ï¼šæ„å»ºç‹¬ç«‹çš„æµ‹è¯•é›†ï¼Œç¡®ä¿ä¸ä¸è®­ç»ƒé›†é‡å ")

    # 1. æ„å»ºè®­ç»ƒé›†é»‘åå•
    blacklist = load_training_questions(TRAIN_FILE)

    # 2. åŠ è½½ GSM8K æµ‹è¯•é›†
    gsm8k_data = load_gsm8k_test_set(blacklist)

    # 3. åŠ è½½å›°éš¾æµ‹è¯•é¢˜
    hard_data = load_hard_test_questions(PARQUET_FILE, blacklist, NUM_HARD_SAMPLES, RANDOM_SEED)

    # 4. ä¿å­˜æµ‹è¯•é›†
    if gsm8k_data or hard_data:
        save_test_set(gsm8k_data, hard_data, OUTPUT_FILE)
    else:
        print("\nâŒ æœªèƒ½è·å–ä»»ä½•æµ‹è¯•æ•°æ®ï¼Œè¯·æ£€æŸ¥è¾“å…¥æ–‡ä»¶å’Œç½‘ç»œè¿æ¥")

if __name__ == "__main__":
    main()